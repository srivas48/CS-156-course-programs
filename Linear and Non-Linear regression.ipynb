{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib \n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([442, 843, 589,  93, 930, 382, 918, 549, 290, 962])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the Dataset for a non-linear hypothesis of the form sign(x1^2 + x2^2 - 1)\n",
    "# Assumptions: Range of values on the x and y axis are the same\n",
    "#              Code is only for classifying data in 2D\n",
    "def gen_data_non_lnr_trnsfrm(llim,ulim,N):\n",
    "    \n",
    "    \"\"\"\n",
    "    llim: a scalar defining the lower limit on the x and y axis\n",
    "    ulim: a scalar defining the upper limit on the x and y axis\n",
    "    target_weight: a column vector of 3x1 listing the known weights used for generating the target hypothesis\n",
    "    N: Total number of data points\n",
    "    Output: Returns a tuple with following elements at respective indices-\n",
    "        index        element\n",
    "        0 -          a numpy array of Nx3 with the first column being all 1s, second and third column \n",
    "                     consists of N points generated uniformly between llim and ulim\n",
    "        1 -          column vector of Nx1, Target hypothesis corresponding to the target weight \n",
    "    \"\"\"\n",
    "    x1_sample = np.append(np.ones((N,1)),np.random.uniform(llim,ulim,N).reshape(N,1),axis=1)\n",
    "    x2_sample = np.random.uniform(llim,ulim,N).reshape(N,1)\n",
    "    data_partial = np.append(x1_sample,x2_sample,axis=1)    \n",
    "    target = (data_partial[:,1]**2).reshape(-1,1) + (data_partial[:,2]**2).reshape(-1,1) - (0.6*np.ones((N,1)))\n",
    "    mask = target>0\n",
    "    category_values_wo_noise = np.where(mask,np.ones((N,1)),-1)\n",
    "    no_of_indices_to_transform = np.int(round(N/10,1))\n",
    "    indices = np.random.randint(0,N,no_of_indices_to_transform)\n",
    "    category_values_with_noise = category_values_wo_noise + np.zeros((N,1))\n",
    "    category_values_with_noise[indices,0] = -category_values_wo_noise[indices,0]\n",
    "    data_complete = np.append(np.append(data_partial,category_values_with_noise,axis=1),category_values_wo_noise,axis=1)\n",
    "    \n",
    "    return data_complete\n",
    "\n",
    "def lin_reg(data_complete):\n",
    "    \"\"\"\n",
    "    data_complete: A numpy array of Nx4 with the first column being all 1s, second and third column \n",
    "                consists of N points generated uniformly between llim and ulim and the last column\n",
    "                contains the categories to be learnt\n",
    "    \n",
    "    Output: Returns an appropriate dimensional column vector of final weights computed using \n",
    "    linear regression system\n",
    "    \"\"\"\n",
    "    a = np.linalg.inv(np.matmul(np.transpose(data_complete[:,0:3]),data_complete[:,0:3]))\n",
    "    b = np.dot(np.transpose(data_complete[:,0:3]),data_complete[:,3].reshape(-1,1))\n",
    "    final_weight = np.dot(a,b)\n",
    "    return final_weight\n",
    "\n",
    "# Function to extract the misclassified values \n",
    "def ident_misclass_pts(data_complete, weight_3D):\n",
    "    \"\"\"\n",
    "    data_complete: A numpy array of Nx5 with the first column being all 1s, second and third column \n",
    "                consists of N points generated uniformly between llim and ulim, the fourth column\n",
    "                contains the categories to be learnt with added noise and the last column contains\n",
    "                the true uncontaminated categories\n",
    "    weight_3D: A column vector of 3x1 specifying weights \n",
    "    \n",
    "    Output: Returns a tuple with the following elements at the respective indices\n",
    "    index   element\n",
    "     index        element\n",
    "        0 - a numpy array of Nx4 containing only the missclassified points and the 4 columns as above \n",
    "        1 - a scalar giving the proportion of missclassified points for the specified weight vector\n",
    "    \n",
    "    \"\"\"\n",
    "    ref_hyp_weight = np.dot(data_complete[:,0:3],weight_3D)\n",
    "    mask = ref_hyp_weight > 0\n",
    "    comp_vec = np.where(mask,np.ones((data_complete.shape[0],1)),-1)\n",
    "    error_mask = comp_vec!=data_complete[:,3].reshape(-1,1)                    \n",
    "    error_mask = np.append(np.append(error_mask,np.append(error_mask,np.append(error_mask,error_mask,axis=1),axis=1),axis=1),error_mask,axis=1)\n",
    "    missclass_data_pts = data_complete[error_mask].reshape(-1,5)\n",
    "    error_frac = missclass_data_pts.shape[0]/data_complete.shape[0]\n",
    "    return (missclass_data_pts,error_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "llim = -1\n",
    "ulim = 1\n",
    "N = 1000\n",
    "nsims = 10000\n",
    "Ein = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average in sample error is:  0.5049529999999994\n"
     ]
    }
   ],
   "source": [
    "# Computing the Ein for multiple linear regression involving just the terms (1,x1,x2)\n",
    "for i in range(nsims):\n",
    "    data_complete = gen_data_non_lnr_trnsfrm(llim,ulim,N)\n",
    "    final_reg_weights = lin_reg(data_complete)\n",
    "    Ein = Ein + ident_misclass_pts(data_complete, final_reg_weights)[1]\n",
    "print(\"The average in sample error is: \", Ein/nsims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average learned weight vector is:  [[ -1.00430845e+00]\n",
      " [  1.12178328e-03]\n",
      " [ -7.09418645e-04]\n",
      " [ -8.20211456e-04]\n",
      " [  1.57604623e+00]\n",
      " [  1.57702279e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Learning the weights for a more complex feature set involving the terms (1,x1,x2,x1*x2,x1^2,x2^2)\n",
    "weights = np.zeros((6,1))\n",
    "for i in range(nsims):\n",
    "    data_complete = gen_data_non_lnr_trnsfrm(llim,ulim,N)\n",
    "    data1 = np.append(np.append(np.append(data_complete[:,0:3],(data_complete[:,1]*data_complete[:,2]).reshape(-1,1),axis=1),(data_complete[:,1]**2).reshape(-1,1),axis=1),(data_complete[:,2]**2).reshape(-1,1),axis=1)\n",
    "    data2 = data_complete[:,3:]\n",
    "    full_feature_dataset = np.append(data1,data2,axis=1)\n",
    "    a = np.linalg.inv(np.matmul(np.transpose(full_feature_dataset[:,0:6]),full_feature_dataset[:,0:6]))\n",
    "    b = np.dot(np.transpose(full_feature_dataset[:,0:6]),(full_feature_dataset[:,6]).reshape(-1,1))\n",
    "    final_reg_weight = np.dot(a,b).reshape(6,1)\n",
    "    weights = weights + final_reg_weight\n",
    "weights = weights/nsims\n",
    "print(\"The average learned weight vector is: \", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average Eout is:  [ 0.1188002]\n"
     ]
    }
   ],
   "source": [
    "# Computing Eout for the average hypothesis calculated in the previous cell for the features\n",
    "# (1,x1,x2,x1*x2,x1^2,x2^2)\n",
    "Eout=0\n",
    "for i in range(nsims):\n",
    "    data_complete = gen_data_non_lnr_trnsfrm(llim,ulim,N)\n",
    "    data1 = np.append(np.append(np.append(data_complete[:,0:3],(data_complete[:,1]*data_complete[:,2]).reshape(-1,1),axis=1),(data_complete[:,1]**2).reshape(-1,1),axis=1),(data_complete[:,2]**2).reshape(-1,1),axis=1)\n",
    "    data2 = data_complete[:,3:]\n",
    "    full_feature_dataset = np.append(data1,data2,axis=1)\n",
    "    ref_hyp_weight = np.dot(full_feature_dataset[:,0:6],weights)\n",
    "    mask = ref_hyp_weight > 0\n",
    "    comp_vec = np.where(mask,np.ones((full_feature_dataset.shape[0],1)),-1)\n",
    "    error_mask = (comp_vec!=full_feature_dataset[:,6].reshape(-1,1)).reshape(-1,1)                    \n",
    "    error_frac = sum(error_mask)/N\n",
    "    Eout = Eout + error_frac\n",
    "print(\"The average Eout is: \",Eout/nsims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
