{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib \n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the Dataset for a known hypothesis\n",
    "# Assumptions: Range of values on the x and y axis are the same\n",
    "#              Code is only for classifying data in 2D\n",
    "def gen_data_perceptron(llim,ulim,target_weight_3D,N):\n",
    "    \n",
    "    \"\"\"\n",
    "    llim: a scalar defining the lower limit on the x and y axis\n",
    "    ulim: a scalar defining the upper limit on the x and y axis\n",
    "    target_weight_3D: a column vector of 3x1 listing the known weights used for generating the target hypothesis\n",
    "    N: Total number of data points\n",
    "    Output: Returns a tuple with following elements at respective indices-\n",
    "        index        element\n",
    "        0 -          a numpy array of Nx4 with the first column being all 1s, second and third column \n",
    "                     consists of N points generated uniformly between llim and ulim\n",
    "    \"\"\"\n",
    "    x1_sample = np.append(np.ones((N,1)),np.random.uniform(llim,ulim,N).reshape(N,1),axis=1)\n",
    "    x2_sample = np.random.uniform(llim,ulim,N).reshape(N,1)\n",
    "    data_partial = np.append(x1_sample,x2_sample,axis=1)    \n",
    "    target = np.dot(data_partial,target_weight_3D)\n",
    "    mask = target>0\n",
    "    category_values = np.where(mask,np.ones((N,1)),-1)\n",
    "    data_complete = np.append(data_partial,category_values,axis=1)\n",
    "    \n",
    "    return data_complete\n",
    "\n",
    "# Function to evaluate the pointwise gradient of the cross entropy error function\n",
    "def grad_eval(weight_current,x_vec,category_val):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    weight_init: current set of weights (a column vector)\n",
    "    x_vec: input point (a 3x1 column vector)\n",
    "    category_val: +1 or -1 depending upon the label of the point\n",
    "    \n",
    "    Output:\n",
    "    Returns the gradient evaluated at the current set of weights(a column vector)\n",
    "    \"\"\"\n",
    "    gradient = -x_vec*category_val/(1 + np.exp(category_val*np.dot(weight_current.reshape(3,),x_vec.reshape(3,))))\n",
    "    return gradient\n",
    "\n",
    "# SGD update for Logistic regression for cross entropy error function\n",
    "def SGD_logistic_regression(weights_init,data_complete,stopping_threshold,eta):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    weight_init: current set of weights (a column vector)\n",
    "    x_vec: input point (a 3x1 column vector)\n",
    "    category_val: +1 or -1 depending upon the label of the point\n",
    "    \n",
    "    Output:\n",
    "    Returns a tuple with following elements at the respective indices:\n",
    "    0 - number of epochs\n",
    "    1 - final set of weights (a 3x1 column vector) \n",
    "    \"\"\"\n",
    "    no_of_epochs = 0\n",
    "    weight_diff = 1\n",
    "    while weight_diff>=stopping_threshold:\n",
    "        weights_old = weights_init + np.zeros((3,1))\n",
    "        order_vec = np.random.permutation(np.arange(data_complete.shape[0]))\n",
    "        for i in order_vec:\n",
    "            x_vec = data_complete[i,0:3].reshape(-1,1)\n",
    "            category_val = data_complete[i,3]\n",
    "            weights_init = weights_init - (eta*grad_eval(weights_init,x_vec,category_val))\n",
    "        diff_vec = (weights_init - weights_old).reshape(3,)\n",
    "        weight_diff = (np.dot(diff_vec,diff_vec))**0.5\n",
    "        no_of_epochs = no_of_epochs + 1\n",
    "    weights_updated = weights_init\n",
    "    #print(\"The number of epochs it took to converge: \", no_of_epochs)\n",
    "    #print(\"The final set of weights are : \", weights_updated)\n",
    "    #print(\"The magnituded of weight difference is : \",weight_diff)\n",
    "    return(no_of_epochs,weights_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.77694911],\n",
       "       [-3.32204369],\n",
       "       [-7.91212046]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the parameters for parameter estimation for Logistic regression model and running SGD\n",
    "llim = -1\n",
    "ulim = 1\n",
    "target_weights_3D = np.random.uniform(llim,ulim,3).reshape(-1,1)\n",
    "N = 100\n",
    "weights_init = np.zeros((3,1))\n",
    "stopping_threshold = 0.01\n",
    "eta = 0.01\n",
    "data_complete = gen_data_perceptron(llim,ulim,target_weights_3D,N)\n",
    "out_res = SGD_logistic_regression(weights_init,data_complete,stopping_threshold,eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average out of sample error is:  0.0848111083495\n"
     ]
    }
   ],
   "source": [
    "# Computing Eout\n",
    "iters_test = 100\n",
    "Eout = 0\n",
    "for i in range(iters_test):\n",
    "    # Training part\n",
    "    target_weights_3D = np.random.uniform(llim,ulim,3).reshape(-1,1)\n",
    "    weights_init = np.zeros((3,1))\n",
    "    data_complete = gen_data_perceptron(llim,ulim,target_weights_3D,N)\n",
    "    out_res = SGD_logistic_regression(weights_init,data_complete,stopping_threshold,eta)\n",
    "    \n",
    "    # Testing part\n",
    "    data_test = gen_data_perceptron(llim,ulim,target_weights_3D,N)\n",
    "    for i in range(N):\n",
    "        Eout = Eout + np.log(1 + np.exp(-data_test[i,3]*np.dot(out_res[1].reshape(3,),data_test[i,0:3])))\n",
    "print(\"The average out of sample error is: \", Eout/(N*iters_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
