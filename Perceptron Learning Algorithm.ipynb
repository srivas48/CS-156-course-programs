{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib \n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the Dataset for a known hypothesis\n",
    "# Assumptions: Range of values on the x and y axis are the same\n",
    "#              Code is only for classifying data in 2D\n",
    "def gen_data_perceptron(llim,ulim,target_weight_3D,N):\n",
    "    \n",
    "    \"\"\"\n",
    "    llim: a scalar defining the lower limit on the x and y axis\n",
    "    ulim: a scalar defining the upper limit on the x and y axis\n",
    "    target_weight: a column vector of 3x1 listing the known weights used for generating the target hypothesis\n",
    "    N: Total number of data points\n",
    "    Output: Returns a numpy array of Nx4 with the first column being all 1s, second and third column \n",
    "                     consists of N points generated uniformly between llim and ulim and the 4th column being \n",
    "                     the labels given as per the target weight\n",
    "    \"\"\"\n",
    "    x1_sample = np.append(np.ones((N,1)),np.random.uniform(llim,ulim,N).reshape(N,1),axis=1)\n",
    "    x2_sample = np.random.uniform(llim,ulim,N).reshape(N,1)\n",
    "    data_partial = np.append(x1_sample,x2_sample,axis=1)    \n",
    "    target = np.dot(data_partial,target_weight_3D)\n",
    "    mask = target>0\n",
    "    category_values = np.where(mask,np.ones((N,1)),-1)\n",
    "    data_complete = np.append(data_partial,category_values,axis=1)\n",
    "    \n",
    "    return data_complete\n",
    "\n",
    "def visual_perceptron(data_complete, weight_3D,t=0):\n",
    "    \"\"\"\n",
    "    data_complete: A numpy array of Nx4 with the first column being all 1s, second and third column \n",
    "                consists of N points generated uniformly between llim and ulim and the last column\n",
    "                contains the categories to be learnt\n",
    "    weight_3D: A column vector of 3x1 specifying weights for my perceprton at any given stage of PLA\n",
    "    t: indicator for target +1 if plotting for the target function and 0 otherwise\n",
    "    \n",
    "    output: Plots the points as separated by the hypothesis under consideration \n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    if t==0:\n",
    "        ax.set_title(\"Visualizing the classification of points with respect to the current hypothesis\")\n",
    "    else:\n",
    "        ax.set_title(\"Visualizing the classification of points with respect to the target function\")\n",
    "    ax.set_xlim([llim, ulim])\n",
    "    ax.set_ylim([llim, ulim])\n",
    "    ax.scatter(data_complete[:,1],data_complete[:,2],c=data_complete[:,3])\n",
    "    ax.plot(data_complete[:,1],(-1/weight_3D[2,0])*(weight_3D[0,0] + (weight_3D[1,0])*data_complete[:,1]))\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "# Function to extract the misclassified points \n",
    "def ident_misclass_pts(data_complete, weight_3D):\n",
    "    \"\"\"\n",
    "    data_complete: A numpy array of Nx4 with the first column being all 1s, second and third column \n",
    "                consists of N points generated uniformly between llim and ulim and the last column\n",
    "                contains the categories to be learnt\n",
    "    weight_3D: A column vector of 3x1 specifying weights for my perceprton at any given stage of PLA\n",
    "    \n",
    "    Output: Returns a tuple with following elements at respective indices-\n",
    "    index        element\n",
    "        0 - a numpy array of Nx4 containing only the missclassified points and the 4 columns as above \n",
    "    \n",
    "    \"\"\"\n",
    "    ref_hyp_weight = np.dot(data_complete[:,0:3],weight_3D)\n",
    "    mask = ref_hyp_weight > 0\n",
    "    comp_vec = np.where(mask,np.ones((data_complete.shape[0],1)),-1)\n",
    "    error_mask = comp_vec!=data_complete[:,3].reshape(-1,1)                    \n",
    "    error_mask = np.append(error_mask,np.append(error_mask,np.append(error_mask,error_mask,axis=1),axis=1),axis=1)\n",
    "    missclass_data_pts = data_complete[error_mask].reshape(-1,4)\n",
    "    return missclass_data_pts\n",
    "\n",
    "# Function to update the weights using a misclassified point\n",
    "def weight_update(weight_current_3D, missclass_pt):\n",
    "    \"\"\"\n",
    "    weights_3D : a 3x1 column vector specifying the current set of weights in 3D\n",
    "    missclass_pt: a missclassified point of shape (4,) with the last entry being the original category \n",
    "    \n",
    "    output: returns a column vector of updated weights in 3D\n",
    "    \"\"\"\n",
    "    if missclass_pt[3]==1:\n",
    "        weight_updated = weight_current_3D + missclass_pt[0:3].reshape(3,1)\n",
    "    else:\n",
    "        weight_updated = weight_current_3D - missclass_pt[0:3].reshape(3,1)\n",
    "    return weight_updated \n",
    "\n",
    "# Perceptron Learning Algorithm\n",
    "def PLA(data_complete, weight_3D_init):\n",
    "    \"\"\"\n",
    "    data_complete : \n",
    "    weights_3D_init : a 3x1 column vector specifying the initial set of weights in 3D \n",
    "    data_complete: A numpy array of Nx4 with the first column being all 1s, second and third column \n",
    "                   consists of N points generated uniformly between llim and ulim and the last column\n",
    "                   contains the categories to be learnt\n",
    "                   \n",
    "    output: Returns a tuple with following elements at respective indices-\n",
    "        index        element\n",
    "        0 -          a column vector 3x1 containing the final weights\n",
    "        1 -          number of iterations until convergence\n",
    "    \"\"\"\n",
    "    missclass_dataset = ident_misclass_pts(data_complete, weight_3D_init)\n",
    "    no_of_iterations=0\n",
    "    while missclass_dataset.size!=0:\n",
    "        n = random.randint(0,missclass_dataset.shape[0]-1)\n",
    "        weight_3D_init = weight_update(weight_3D_init, missclass_dataset[n])\n",
    "        missclass_dataset = ident_misclass_pts(data_complete, weight_3D_init)\n",
    "        no_of_iterations = no_of_iterations + 1\n",
    "    final_weight = weight_3D_init\n",
    "    #visual_perceptron(data_complete, final_weight)\n",
    "    return (final_weight,no_of_iterations)    \n",
    "\n",
    "# Counting the disagreement between target function and learned hypothesis\n",
    "def disag_func(data_complete,final_weight,N):\n",
    "    learned = np.dot(data_complete[:,0:3],final_weight)\n",
    "    mask = learned>0\n",
    "    learned_category_values = np.where(mask,np.ones((N,1)),-1)\n",
    "    disagreement_prop = sum(learned_category_values!=data_complete[:,3].reshape(-1,1))/N\n",
    "    return disagreement_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the average disagreement and average number of iterations to converge\n",
    "nsims = 1000\n",
    "disag = 0\n",
    "iters = 0\n",
    "llim = -1\n",
    "ulim = 1\n",
    "N = 100\n",
    "for i in range(nsims):\n",
    "    target_weight_3D = np.array([[np.random.uniform(-1,1)],[np.random.uniform(-1,1)],[np.random.uniform(-1,1)]])\n",
    "    data_complete = gen_data_perceptron(llim,ulim,target_weight_3D,N)\n",
    "    \n",
    "    # Running the Perceptron Learning Algorithm\n",
    "    weight_3D_init = np.array([[0],[0],[0]])\n",
    "    final_result = PLA(data_complete, weight_3D_init)\n",
    "    iters = iters + final_result[1]\n",
    "    \n",
    "    # Generating test data set for computing the disagreement\n",
    "    data_test = gen_data_perceptron(llim,ulim,target_weight_3D,N)\n",
    "    disag = disag + disag_func(data_test,final_result[0],N)\n",
    "    \n",
    "print(\"The proportion of disagreement between the target function and learned hypothesis:\", disag/nsims)\n",
    "print(\"The average number of iterations the algorithm takes to converge: \",iters/nsims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
