{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib \n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "from statistics import mean \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to train SVM on a model and compute the error on any specified dataset\n",
    "def regul_regression_analysis(data_training,data_testing,plus_one_label,reg_param,minus_one_label=10):\n",
    "    \"\"\"\n",
    "    Inputs-\n",
    "    data_training: A Pandas dataframe of Nx3 to be used as a training set where the first column is the specific digit, second column\n",
    "                   is the intensity and third is symmetry\n",
    "    data_testing: A Pandas dataframe of Nx3 to be used as a test set where the first column is the specific digit, second column\n",
    "                   is the intensity and third is symmetry\n",
    "    plus_one_label: digit to be assigned the label +1\n",
    "    minus_one_label: digit to be assigned -1 label, only valid if we are doing one digit versus another one\n",
    "                     with all others being disregarded (by default it is 10)\n",
    "    reg_param: Regularization parameter\n",
    "    \n",
    "    Output-\n",
    "    error_regression - computes the error of the model on the dataset specified for testing\n",
    "    \"\"\"\n",
    "    # Preparing the Dataset\n",
    "    if 0<=minus_one_label<10:\n",
    "        data_training = data_training.loc[(data_training['digit']==plus_one_label) | (data_training['digit']==minus_one_label)]\n",
    "        data_testing = data_testing.loc[(data_testing['digit']==plus_one_label) | (data_testing['digit']==minus_one_label)] \n",
    "    train_data = data_training.values\n",
    "    test_data = data_testing.values\n",
    "    y_train = (np.where(data_training['digit']==plus_one_label, 1, -1)).reshape(-1,1)\n",
    "    y_test = (np.where(data_testing['digit']==plus_one_label, 1, -1)).reshape(-1,1)\n",
    "    X_train = train_data[:,1:-1]\n",
    "    X_test = test_data[:,1:-1]\n",
    "    # Fitting the Regularized Linear Regression Model\n",
    "    n = X_train.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "    d = X_train.shape[1]\n",
    "    X_train_design = np.append(np.ones((n,1)),X_train,axis=1)  \n",
    "    X_test_design = np.append(np.ones((n_test,1)),X_test,axis=1)\n",
    "    a = np.linalg.inv(np.matmul(np.transpose(X_train_design),X_train_design) + (reg_param*np.identity(d+1)))\n",
    "    b = np.dot(np.transpose(X_train_design),y_train)\n",
    "    final_weight = (np.dot(a,b)).reshape(-1,1)\n",
    "    \n",
    "    # Making predictions and computing the error\n",
    "    pred_regress = (np.dot(X_test_design,final_weight)).reshape(-1,1)\n",
    "    err_vec = (pred_regress.reshape(-1,))*(y_test.reshape(-1,))\n",
    "    error_regress = np.sum(err_vec < 0)/n_test\n",
    "    return error_regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Digit Training and Test datasets\n",
    "train_data = pd.read_csv('digit_identification_training.txt', sep=\"\\t\")\n",
    "test_data = pd.read_csv('digit_identification_testing.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum in sample error among the digits in digits_vec is observed for :  8\n"
     ]
    }
   ],
   "source": [
    "# Regularization problems\n",
    "# Problem 7\n",
    "Ein_vec = []\n",
    "reg_param = 1\n",
    "digits_vec = [5,6,7,8,9]\n",
    "for i in digits_vec:\n",
    "    Ein_vec.append(regul_regression_analysis(train_data,train_data,i,reg_param,minus_one_label=10))\n",
    "print(\"The minimum in sample error among the digits in digits_vec is observed for : \",digits_vec[Ein_vec.index(min(Ein_vec))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 8\n",
    "Ein_overall_vec_wot = []\n",
    "Eout_overall_vec_wot = []\n",
    "digits_vec = [0,1,2,3,4,5,6,7,8,9]\n",
    "for i in digits_vec:\n",
    "    Ein_overall_vec_wot.append(regul_regression_analysis(train_data,train_data,i,reg_param,minus_one_label=10))\n",
    "    Eout_overall_vec_wot.append(regul_regression_analysis(train_data,test_data,i,reg_param,minus_one_label=10))\n",
    "print(\"The in sample error vector without transformation : \",Ein_overall_vec_wot)\n",
    "print(\"The out-of-sample error vector without transformation: \",Eout_overall_vec_wot)\n",
    "\n",
    "train_data['x1_sq'] = train_data['intensity']**2\n",
    "train_data['x2_sq'] = train_data['symmetry']**2\n",
    "train_data['x1_x2'] = train_data['intensity']*train_data['symmetry']\n",
    "test_data['x1_sq'] = test_data['intensity']**2\n",
    "test_data['x2_sq'] = test_data['symmetry']**2\n",
    "test_data['x1_x2'] = test_data['intensity']*test_data['symmetry']\n",
    "\n",
    "Ein_overall_vec_wt = []\n",
    "Eout_overall_vec_wt = []\n",
    "for i in digits_vec:\n",
    "    Ein_overall_vec_wt.append(regul_regression_analysis(train_data,train_data,i,reg_param,minus_one_label=10))\n",
    "    Eout_overall_vec_wt.append(regul_regression_analysis(train_data,test_data,i,reg_param,minus_one_label=10))\n",
    "print(\"The in sample error vector with transformation: \",Ein_overall_vec_wt)\n",
    "print(\"The out of sample error vector with transformation : \",Eout_overall_vec_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observed out of sample error vector is:  [0.1111111111111111, 0.02242152466367713, 0.09865470852017937, 0.08271051320378675, 0.09965122072745392]\n",
      "The minimum in sample error among the digits in digits_vec is observed for :  1\n"
     ]
    }
   ],
   "source": [
    "# Problem 9\n",
    "Eout_vec=[]\n",
    "digits_vec = [0,1,2,3,4]\n",
    "for i in digits_vec:\n",
    "    Eout_vec.append(regul_regression_analysis(train_data,test_data,i,reg_param,minus_one_label=10))\n",
    "print(\"The observed out of sample error vector is: \", Eout_vec)\n",
    "print(\"The minimum in sample error among the digits in digits_vec is observed for : \",digits_vec[Eout_vec.index(min(Eout_vec))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The in sample error vector for the two values of regularization parameter is:  [0.005124919923126201, 0.005124919923126201]\n",
      "The out-of-sample error vector for the two values of regularization parameter is:  [0.02830188679245283, 0.025943396226415096]\n"
     ]
    }
   ],
   "source": [
    "# Problem 10\n",
    "reg_params_vec = [0.01,1]\n",
    "Ein_reg_vec = []\n",
    "Eout_reg_vec = []\n",
    "for j in reg_params_vec:\n",
    "    Ein_reg_vec.append(regul_regression_analysis(train_data,train_data,plus_one_label=1,reg_param=j,minus_one_label=5))\n",
    "    Eout_reg_vec.append(regul_regression_analysis(train_data,test_data,plus_one_label=1,reg_param=j,minus_one_label=5))\n",
    "print(\"The in sample error vector for the two values of regularization parameter is: \", Ein_reg_vec)\n",
    "print(\"The out-of-sample error vector for the two values of regularization parameter is: \", Eout_reg_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we move from lambda=1 to lambda=0.01 we can clearly see that overfitting occurs as the testing error increases with no change in training error. This implies that 0.01 is not enough strength to overpower the complicated set of features we are using and we need to use a larger value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM problems\n",
    "\n",
    "# Problem 11\n",
    "# Transforming x1,x2 into z1 and z2\n",
    "def transform_fun(a,b):\n",
    "    return (b**2 - 2*a - 1,a**2 - 2*b + 1)\n",
    "x = [(1,0),(0,1),(0,-1),(-1,0),(0,2),(0,-2),(-2,0)]\n",
    "y = [-1,-1,-1,1,1,1,1]\n",
    "z1 = []\n",
    "z2 = []\n",
    "for i in x:\n",
    "    temp = transform_fun(i[0],i[1])\n",
    "    z1.append(temp[0])\n",
    "    z2.append(temp[1])\n",
    "\n",
    "# Plotting the points\n",
    "fig = plt.figure() \n",
    "ax = fig.add_subplot(111) \n",
    "ax.set_xlim(-4, 4)\n",
    "ax.set_title('Points in z1-z2 system')\n",
    "ax.set_ylabel('Z2')\n",
    "ax.set_xlabel('Z1')\n",
    "ax.scatter(z1, z2, c=[1, 1, 1, 2,2,2,2], marker='^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the location of points it is pretty clear that z1-0.5=0 line clearly separates the points into two categories as dictated in the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 12\n",
    "data_svm = (np.array([z1,z2])).reshape(-1,2)\n",
    "resp_svm = (np.array([y])).reshape(-1,)\n",
    "clf = svm.SVC(C=1e20, degree=2, kernel='poly',gamma=1,coef0=1)\n",
    "svm_fit = clf.fit(data_svm, resp_svm)\n",
    "print(\"The number of support vectors are: \",(svm_fit.support_vectors_).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing standalone RBFs with RBF kernels being used in SVM \n",
    "def gen_data_rbf(llim,ulim,N):\n",
    "    \n",
    "    \"\"\"\n",
    "    llim: a scalar defining the lower limit on the x and y axis\n",
    "    ulim: a scalar defining the upper limit on the x and y axis\n",
    "    N: Total number of data points\n",
    "    Output: Returns a numpy array of Nx3 where the first and second column \n",
    "            consists of N points generated uniformly between llim and ulim and the 3th column being \n",
    "            the labels given as per the target function\n",
    "    \"\"\"\n",
    "    x1 = (np.random.uniform(llim,ulim,N)).reshape(N,1)\n",
    "    x2 = (np.random.uniform(llim,ulim,N)).reshape(N,1)\n",
    "    data_partial = np.append(x1,x2,axis=1)    \n",
    "    target = x2 - x1 + (0.25*np.sin(np.pi*x1))\n",
    "    mask = target>0\n",
    "    category_values = np.where(mask,np.ones((N,1)),-1)\n",
    "    data_complete = np.append(data_partial,category_values,axis=1)\n",
    "    \n",
    "    return data_complete\n",
    "\n",
    "def vis_target_classification(data_complete):\n",
    "    \"\"\"\n",
    "    data_complete: Returns a numpy array of Nx3 where the first and second column \n",
    "                   consists of N points generated uniformly between llim and ulim and the 3th column being \n",
    "                   the labels given as per the target function\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure() \n",
    "    ax = fig.add_subplot(111) \n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_title('Points separated by f=x2-x1 + 0.25*sin(pi*x1)')\n",
    "    ax.set_ylabel('x1')\n",
    "    ax.set_xlabel('x2')\n",
    "    ax.scatter(data_complete[:,0],data_complete[:,1], c=data_complete[:,2], marker='^')\n",
    "    plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the problem parameters\n",
    "llim=-1\n",
    "ulim=1\n",
    "N = 100\n",
    "iters = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of times hard margin SVM fails to classify all the in sample points correctly is:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Problem 13: Fitting the SVM to compute the proportion of misspecification for hard margins\n",
    "clf = svm.SVC(C=1e20,kernel='rbf',gamma=1.5)\n",
    "iter_incorrect = 0\n",
    "for i in range(iters):\n",
    "    data_temp = gen_data_rbf(llim,ulim,N)\n",
    "    svm_fit = clf.fit(data_temp[:,0:2], (data_temp[:,2]).reshape(-1,))\n",
    "    pred_svm = (svm_fit.predict(data_temp[:,0:2])).reshape(-1,1)\n",
    "    error_SVM = np.mean(pred_svm!=((data_temp[:,2]).reshape(-1,1)))\n",
    "    if error_SVM!=0:\n",
    "        iter_incorrect = iter_incorrect + 1\n",
    "print(\"The proportion of times hard margin SVM fails to classify all the in sample points correctly is: \",iter_incorrect/iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group of functions estimate the centres in an RBF kernel using Lloyd's algorithm and \n",
    "# compute the weights using Linear regression\n",
    "def computing_clusters(data_partial,centres):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    data_partial: Nxr numpy array containing only the design columns(excluding 1s and responses/categories)\n",
    "    centres: Kxr numpy array where K corresponds to the number of clusters and r is the dimension of input \n",
    "             space\n",
    "             \n",
    "    Output\n",
    "    cluster_matrix: K X N numpy array whose (i,j) point corresponds to the following\n",
    "                    - 0 if jth point doesn't belongs to the cluster\n",
    "                    - i if jth point belongs to the cluster \n",
    "    \"\"\"\n",
    "    K = centres.shape[0]\n",
    "    N = data_partial.shape[0]\n",
    "    cluster_matrix = np.zeros((K,N))\n",
    "    for i in range(N):\n",
    "        dist_point = (np.sum(np.power(((data_partial[i,:]).reshape(-1,)) - centres,2),axis=1)).reshape(K,)\n",
    "        cluster_matrix[:,i] = dist_point\n",
    "        mask = cluster_matrix[:,i]==np.amin(cluster_matrix[:,i])\n",
    "        cluster_matrix[:,i]= (np.where(mask,np.argmin(cluster_matrix[:,i])+1,0)).reshape(K,)\n",
    "    return cluster_matrix\n",
    "\n",
    "def updating_centres(data_partial,cluster_matrix):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    data_partial: Nxr numpy array containing only the design columns(excluding 1s and responses/categories)\n",
    "    cluster_matrix: K X N numpy array whose (i,j) point corresponds to the following\n",
    "                    - 0 if jth point doesn't belongs to the cluster\n",
    "                    - i if jth point belongs to the cluster\n",
    "    \n",
    "    Output\n",
    "    updated_centres: A numpy array of K x r giving the updated weights as the means of computed clusters\n",
    "    \"\"\"\n",
    "    K = cluster_matrix.shape[0]\n",
    "    r = data_partial.shape[1]\n",
    "    updated_centres = np.zeros((K,r)) \n",
    "    for i in range(K):\n",
    "        inds = np.argwhere(cluster_matrix==i)\n",
    "        if inds.size==0: # test for an insolvable clustering situation\n",
    "            updated_centres = np.ones((K,r)) \n",
    "            break\n",
    "        else:\n",
    "            inds = inds[:,1]\n",
    "            updated_centres[i,:] = (np.mean(data_partial[inds,:],axis=0)).reshape(r,)\n",
    "    return updated_centres\n",
    "\n",
    "def lloyd_algorithm(data_partial,centres):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    data_partial: Nxr numpy array containing only the design columns(excluding 1s and responses/categories)\n",
    "    centres: Kxr numpy array where K corresponds to the number of clusters and r is the dimension of input \n",
    "             space\n",
    "             \n",
    "    Output\n",
    "    final_centres: K X r numpy array containing the final centres for each of the clusters\n",
    "    \"\"\"\n",
    "    cm = computing_clusters(data_partial,centres)\n",
    "    cm1 = cm+10\n",
    "    while (np.all(cm==cm1)!=True): \n",
    "        centres = updating_centres(data_partial,cm)\n",
    "        if np.all(centres==1)==True:\n",
    "            break\n",
    "        else:\n",
    "            cm1 = computing_clusters(data_partial,centres)\n",
    "        if np.all(cm==cm1)==True:\n",
    "            break\n",
    "        else:\n",
    "            cm=cm1\n",
    "    return centres\n",
    "\n",
    "def rbf_kerel_weights(data_partial,response_categories_train,gamma,centres):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    data_partial: Nxr numpy array containing only the design columns(excluding 1s and responses/categories)\n",
    "    response_categories_train: (N,1) or (N,) numpy array containing the response categories based on target function\n",
    "    gamma: scaling factor for the RBF kernel\n",
    "    centres: Kxr numpy array where K corresponds to the number of clusters and r is the dimension of input \n",
    "             space\n",
    "             \n",
    "    Output\n",
    "    final_weights: numpy array of shape (K+1,1) containing the estimated weights associated with each of the cluster \n",
    "                   terms\n",
    "    \"\"\"\n",
    "    K = centres.shape[0]\n",
    "    N = data_partial.shape[0]\n",
    "    design_matrix = np.zeros((N,K))\n",
    "    for i in range(N):\n",
    "        dist_point = np.exp(-gamma*((np.sum(np.power(((data_partial[i,:]).reshape(-1,)) - centres,2),axis=1)).reshape(K,)))\n",
    "        design_matrix[i,:] = dist_point\n",
    "    design_matrix = np.append(np.ones((N,1)),design_matrix,axis=1)\n",
    "    a = np.linalg.inv(np.matmul(np.transpose(design_matrix),design_matrix))\n",
    "    b = np.dot(np.transpose(design_matrix),response_categories_train.reshape(-1,1))\n",
    "    final_weights = np.dot(a,b)\n",
    "    return final_weights\n",
    "\n",
    "def pred_rbf_kernel(data_partial_test,response_categories_test,final_centres,final_weights,gamma):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    data_partial_test: Nxr numpy array containing only the design columns(excluding 1s and responses/categories)\n",
    "    response_categories_test: (N,1) or (N,) numpy array containing the response categories based on target function\n",
    "    gamma: scaling factor for the RBF kernel\n",
    "    final_centres: Kxr numpy array where K corresponds to the number of clusters and r is the dimension of input \n",
    "             space\n",
    "    final_weights: numpy array of shape (K+1,1) containing the estimated weights associated with each of \n",
    "                   the cluster terms\n",
    "    \n",
    "    Output\n",
    "    error: total error made by the RBF using the binary classification error measure\n",
    "    \"\"\"\n",
    "    K = final_centres.shape[0]\n",
    "    N = data_partial_test.shape[0]\n",
    "    design_matrix_test = np.zeros((N,K))\n",
    "    for i in range(N):\n",
    "        dist_point = np.exp(-gamma*((np.sum(np.power(((data_partial_test[i,:]).reshape(-1,)) - final_centres,2),axis=1)).reshape(K,)))\n",
    "        design_matrix_test[i,:] = dist_point\n",
    "    design_matrix_test = np.append(np.ones((N,1)),design_matrix_test,axis=1)\n",
    "    pred_rbf_rval = (np.dot(design_matrix_test,final_weights)).reshape(-1,)\n",
    "    mask = pred_rbf_rval>0\n",
    "    pred_category_values = np.where(mask,1,-1)\n",
    "    error_rbf = np.mean(pred_category_values!=(response_categories_test.reshape(-1,1)))\n",
    "    return error_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem 14: K=9 gamma=1.5\n",
    "K = 9\n",
    "iters = 1000\n",
    "gamma=1.5\n",
    "SVM_better_than_rbf = 0\n",
    "for i in range(iters):\n",
    "    # Generating the Dataset for ith iteration\n",
    "    error_train_SVM=0.1\n",
    "    cond=True\n",
    "    while (error_train_SVM!=0) or (cond==True):\n",
    "        data_temp_train = gen_data_rbf(llim,ulim,N)\n",
    "        data_temp_test = gen_data_rbf(llim,ulim,N)\n",
    "        svm_fit = clf.fit(data_temp_train[:,0:2], (data_temp_train[:,2]).reshape(-1,))\n",
    "        pred_svm_train = (svm_fit.predict(data_temp_train[:,0:2])).reshape(-1,1)\n",
    "        error_train_SVM = np.mean(pred_svm_train!=((data_temp_train[:,2]).reshape(-1,1)))\n",
    "        \n",
    "        response_categories_train = data_temp_train[:,2]\n",
    "        response_categories_test = data_temp_test[:,2]\n",
    "        centres_init = (np.random.uniform(llim,ulim,2*K)).reshape(K,-1)\n",
    "        final_centres = lloyd_algorithm(data_temp_train[:,0:2],centres_init)\n",
    "        cond = np.all(final_centres==1)\n",
    "        \n",
    "    pred_svm = (svm_fit.predict(data_temp_test[:,0:2])).reshape(-1,1)\n",
    "    error_test_SVM = np.mean(pred_svm!=((data_temp_test[:,2]).reshape(-1,1)))\n",
    "    final_weights = rbf_kerel_weights(data_temp_train[:,0:2],response_categories_train,gamma,final_centres)\n",
    "    error_test_rbf = pred_rbf_kernel(data_temp_test[:,0:2],response_categories_test,final_centres,final_weights,gamma)\n",
    "    \n",
    "    if error_test_rbf>error_test_SVM:\n",
    "        SVM_better_than_rbf = SVM_better_than_rbf + 1\n",
    "SVM_better_than_rbf/iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem 15: K=12 gamma=1.5\n",
    "K = 12\n",
    "iters = 10000\n",
    "gamma=1.5\n",
    "SVM_better_than_rbf = 0\n",
    "for i in range(iters):\n",
    "    # Generating the Dataset for ith iteration\n",
    "    error_train_SVM=0.1\n",
    "    cond=True\n",
    "    while (error_train_SVM!=0) or (cond==True):\n",
    "        data_temp_train = gen_data_rbf(llim,ulim,N)\n",
    "        data_temp_test = gen_data_rbf(llim,ulim,N)\n",
    "        svm_fit = clf.fit(data_temp_train[:,0:2], (data_temp_train[:,2]).reshape(-1,))\n",
    "        pred_svm_train = (svm_fit.predict(data_temp_train[:,0:2])).reshape(-1,1)\n",
    "        error_train_SVM = np.mean(pred_svm_train!=((data_temp_train[:,2]).reshape(-1,1)))\n",
    "        \n",
    "        response_categories_train = data_temp_train[:,2]\n",
    "        response_categories_test = data_temp_test[:,2]\n",
    "        centres_init = (np.random.uniform(llim,ulim,2*K)).reshape(K,-1)\n",
    "        final_centres = lloyd_algorithm(data_temp_train[:,0:2],centres_init)\n",
    "        cond = np.all(final_centres==1)\n",
    "        \n",
    "    pred_svm = (svm_fit.predict(data_temp_test[:,0:2])).reshape(-1,1)\n",
    "    error_test_SVM = np.mean(pred_svm!=((data_temp_test[:,2]).reshape(-1,1)))\n",
    "    final_weights = rbf_kerel_weights(data_temp_train[:,0:2],response_categories_train,gamma,final_centres)\n",
    "    error_test_rbf = pred_rbf_kernel(data_temp_test[:,0:2],response_categories_test,final_centres,final_weights,gamma)\n",
    "    \n",
    "    if error_test_rbf>error_test_SVM:\n",
    "        SVM_better_than_rbf = SVM_better_than_rbf + 1\n",
    "SVM_better_than_rbf/iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 16: Comparing K=9 with K=12 for RBF\n",
    "iters=10000\n",
    "Error9_rbf = []\n",
    "Error12_rbf = []\n",
    "no_k = [9,12]\n",
    "gamma = 1.5\n",
    "for K in no_k:\n",
    "    for i in range(iters):\n",
    "        # Generating the Dataset for ith iteration\n",
    "        cond=True\n",
    "        while cond==True:\n",
    "            data_temp_train = gen_data_rbf(llim,ulim,N)\n",
    "            data_temp_test = gen_data_rbf(llim,ulim,N)\n",
    "            response_categories_train = data_temp_train[:,2]\n",
    "            response_categories_test = data_temp_test[:,2]\n",
    "            centres_init = (np.random.uniform(llim,ulim,2*K)).reshape(K,-1)\n",
    "            final_centres = lloyd_algorithm(data_temp_train[:,0:2],centres_init)\n",
    "            cond = np.all(final_centres==1)\n",
    "\n",
    "        final_weights = rbf_kerel_weights(data_temp_train[:,0:2],response_categories_train,gamma,final_centres)\n",
    "        error_test_rbf = pred_rbf_kernel(data_temp_test[:,0:2],response_categories_test,final_centres,final_weights,gamma)\n",
    "        error_train_rbf = pred_rbf_kernel(data_temp_train[:,0:2],response_categories_train,final_centres,final_weights,gamma)\n",
    "        if K==9:\n",
    "            Error9_rbf.append((error_train_rbf,error_test_rbf))\n",
    "        else:\n",
    "            Error12_rbf.append((error_train_rbf,error_test_rbf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times Ein increases and Eout decreases 2368\n",
      "Number of times for which Ein decreases and Eout increases 2265\n",
      "Number of times for which both Ein and Eout decrease 2333\n",
      "Number of times for which Ein and Eout increase 2249\n",
      "Number of times for which Ein and Eout stay the same 12\n",
      "Number of times for which Ein=0 for K=9 RBF kernel 0\n"
     ]
    }
   ],
   "source": [
    "Einin = []\n",
    "Eoutout = []\n",
    "for j in range(iters):\n",
    "    Einin.append(Error9_rbf[j][0] - Error12_rbf[j][0])\n",
    "    Eoutout.append((Error9_rbf[j])[1] - (Error12_rbf[j])[1])\n",
    "\n",
    "m = 0\n",
    "n = 0\n",
    "o=0\n",
    "p=0\n",
    "q=0\n",
    "s=0\n",
    "for l in range(iters):\n",
    "    if Einin[l]<0 and Eoutout[l]>0: # Ein increases but Eout decreases\n",
    "        m = m+1\n",
    "    elif Einin[l]>0 and Eoutout[l]<0: # Ein decreases but Eout increases\n",
    "        n = n+1\n",
    "    elif Einin[l]>0 and Eoutout[l]>0: # Both Ein and Eout decrease\n",
    "        o = o + 1\n",
    "    elif Einin[l]<0 and Eoutout[l]<0: # Both Ein and Eout increase\n",
    "        p = p + 1\n",
    "    elif Einin[l]==0 and Eoutout[l]==0: # Both Ein and Eout stay constant\n",
    "        q = q + 1  \n",
    "    if Error9_rbf[j][0]==0: # number of times Ein=0 for kernel with K=9 and gamma=1.5\n",
    "        s = s + 1\n",
    "print(\"Number of times Ein increases and Eout decreases\",m)\n",
    "print(\"Number of times for which Ein decreases and Eout increases\",n)\n",
    "print(\"Number of times for which both Ein and Eout decrease\",o)\n",
    "print(\"Number of times for which Ein and Eout increase\",p)\n",
    "print(\"Number of times for which Ein and Eout stay the same\",q)\n",
    "print(\"Number of times for which Ein=0 for K=9 RBF kernel\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 17: Comparing gamma=1.5 with gamma=2 for RBF with K=9\n",
    "iters=10000\n",
    "gamma15_rbf = []\n",
    "gamma2_rbf = []\n",
    "K=9\n",
    "gamma_vec = [1.5,2]\n",
    "for gamma in gamma_vec:\n",
    "    for i in range(iters):\n",
    "        # Generating the Dataset for ith iteration\n",
    "        cond=True\n",
    "        while cond==True:\n",
    "            data_temp_train = gen_data_rbf(llim,ulim,N)\n",
    "            data_temp_test = gen_data_rbf(llim,ulim,N)\n",
    "            response_categories_train = data_temp_train[:,2]\n",
    "            response_categories_test = data_temp_test[:,2]\n",
    "            centres_init = (np.random.uniform(llim,ulim,2*K)).reshape(K,-1)\n",
    "            final_centres = lloyd_algorithm(data_temp_train[:,0:2],centres_init)\n",
    "            cond = np.all(final_centres==1)\n",
    "\n",
    "        final_weights = rbf_kerel_weights(data_temp_train[:,0:2],response_categories_train,gamma,final_centres)\n",
    "        error_test_rbf = pred_rbf_kernel(data_temp_test[:,0:2],response_categories_test,final_centres,final_weights,gamma)\n",
    "        error_train_rbf = pred_rbf_kernel(data_temp_train[:,0:2],response_categories_train,final_centres,final_weights,gamma)\n",
    "        if gamma==1.5:\n",
    "            gamma15_rbf.append((error_train_rbf,error_test_rbf))\n",
    "        else:\n",
    "            gamma2_rbf.append((error_train_rbf,error_test_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times Ein increases and Eout decreases 2396\n",
      "Number of times for which Ein decreases and Eout increases 2350\n",
      "Number of times for which both Ein and Eout decrease 2229\n",
      "Number of times for which Ein and Eout increase 2300\n",
      "Number of times for which Ein and Eout stay the same 15\n"
     ]
    }
   ],
   "source": [
    "Einin = []\n",
    "Eoutout = []\n",
    "for j in range(iters):\n",
    "    Einin.append(gamma15_rbf[j][0] - gamma2_rbf[j][0])\n",
    "    Eoutout.append((gamma15_rbf[j])[1] - (gamma2_rbf[j])[1])\n",
    "\n",
    "m = 0\n",
    "n = 0\n",
    "o=0\n",
    "p=0\n",
    "q=0\n",
    "for l in range(iters):\n",
    "    if Einin[l]<0 and Eoutout[l]>0: # Ein increases but Eout decreases\n",
    "        m = m+1\n",
    "    elif Einin[l]>0 and Eoutout[l]<0: # Ein decreases but Eout increases\n",
    "        n = n+1\n",
    "    elif Einin[l]>0 and Eoutout[l]>0: # Both Ein and Eout decrease\n",
    "        o = o + 1\n",
    "    elif Einin[l]<0 and Eoutout[l]<0: # Both Ein and Eout increase\n",
    "        p = p + 1\n",
    "    elif Einin[l]==0 and Eoutout[l]==0: # Both Ein and Eout stay constant\n",
    "        q = q + 1   \n",
    "print(\"Number of times Ein increases and Eout decreases\",m)\n",
    "print(\"Number of times for which Ein decreases and Eout increases\",n)\n",
    "print(\"Number of times for which both Ein and Eout decrease\",o)\n",
    "print(\"Number of times for which Ein and Eout increase\",p)\n",
    "print(\"Number of times for which Ein and Eout stay the same\",q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
