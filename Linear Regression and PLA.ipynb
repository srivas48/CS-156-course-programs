{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib \n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the Dataset for a known hypothesis\n",
    "# Assumptions: Range of values on the x and y axis are the same\n",
    "#              Code is only for classifying data in 2D\n",
    "def gen_data_perceptron(llim,ulim,target_weight_3D,N):\n",
    "    \n",
    "    \"\"\"\n",
    "    llim: a scalar defining the lower limit on the x and y axis\n",
    "    ulim: a scalar defining the upper limit on the x and y axis\n",
    "    target_weight: a column vector of 3x1 listing the known weights used for generating the target hypothesis\n",
    "    N: Total number of data points\n",
    "    Output: Returns a tuple with following elements at respective indices-\n",
    "        index        element\n",
    "        0 -          a numpy array of Nx3 with the first column being all 1s, second and third column \n",
    "                     consists of N points generated uniformly between llim and ulim\n",
    "        1 -          column vector of Nx1, Target hypothesis corresponding to the target weight \n",
    "    \"\"\"\n",
    "    x1_sample = np.append(np.ones((N,1)),np.random.uniform(llim,ulim,N).reshape(N,1),axis=1)\n",
    "    x2_sample = np.random.uniform(llim,ulim,N).reshape(N,1)\n",
    "    data_partial = np.append(x1_sample,x2_sample,axis=1)    \n",
    "    target = np.dot(data_partial,target_weight_3D)\n",
    "    mask = target>0\n",
    "    category_values = np.where(mask,np.ones((N,1)),-1)\n",
    "    data_complete = np.append(data_partial,category_values,axis=1)\n",
    "    \n",
    "    return data_complete\n",
    "\n",
    "# Function to compute the Linear Regression solution\n",
    "def lin_reg(data_complete):\n",
    "    \"\"\"\n",
    "    data_complete: A numpy array of Nx4 with the first column being all 1s, second and third column \n",
    "                consists of N points generated uniformly between llim and ulim and the last column\n",
    "                contains the categories to be learnt\n",
    "    \n",
    "    Output: Returns a 3x1 column vector of final weights computed using the linear regression\n",
    "    \"\"\"\n",
    "    a = np.linalg.inv(np.matmul(np.transpose(data_complete[:,0:3]),data_complete[:,0:3]))\n",
    "    b = np.dot(np.transpose(data_complete[:,0:3]),data_complete[:,3].reshape(-1,1))\n",
    "    final_weight = np.dot(a,b)\n",
    "    return final_weight\n",
    "    \n",
    "# Function to extract the misclassified values \n",
    "def ident_misclass_pts(data_complete, weight_3D):\n",
    "    \"\"\"\n",
    "    data_complete: A numpy array of Nx4 with the first column being all 1s, second and third column \n",
    "                consists of N points generated uniformly between llim and ulim and the last column\n",
    "                contains the categories to be learnt\n",
    "    weight_3D: A column vector of 3x1 specifying weights \n",
    "    \n",
    "    Output: Returns a tuple with the following elements at the respective indices\n",
    "    index   element\n",
    "     index        element\n",
    "        0 - a numpy array of Nx4 containing only the missclassified points and the 4 columns as above \n",
    "        1 - a scalar giving the proportion of missclassified points for the specified weight vector\n",
    "    \n",
    "    \"\"\"\n",
    "    ref_hyp_weight = np.dot(data_complete[:,0:3],weight_3D)\n",
    "    mask = ref_hyp_weight > 0\n",
    "    comp_vec = np.where(mask,np.ones((data_complete.shape[0],1)),-1)\n",
    "    error_mask = comp_vec!=data_complete[:,3].reshape(-1,1)                    \n",
    "    error_mask = np.append(error_mask,np.append(error_mask,np.append(error_mask,error_mask,axis=1),axis=1),axis=1)\n",
    "    missclass_data_pts = data_complete[error_mask].reshape(-1,4)\n",
    "    error_frac = missclass_data_pts.shape[0]/data_complete.shape[0]\n",
    "    return (missclass_data_pts,error_frac)\n",
    "\n",
    "# Function to update the weights for PLA using a misclassified point\n",
    "def weight_update(weight_current_3D, missclass_pt):\n",
    "    \"\"\"\n",
    "    weights_3D : a 3x1 column vector specifying the current set of weights in 3D\n",
    "    missclass_pt: a missclassified point of shape (4,) with the last entry being the original category \n",
    "    \n",
    "    output: returns a column vector of updated weights in 3D\n",
    "    \"\"\"\n",
    "    if missclass_pt[3]==1:\n",
    "        weight_updated = weight_current_3D + missclass_pt[0:3].reshape(3,1)\n",
    "    else:\n",
    "        weight_updated = weight_current_3D - missclass_pt[0:3].reshape(3,1)\n",
    "    return weight_updated\n",
    "\n",
    "# Perceptron Learning Algorithm\n",
    "def PLA(data_complete, weight_3D_init):\n",
    "    \"\"\"\n",
    "    data_complete : \n",
    "    weights_3D_init : a 3x1 column vector specifying the initial set of weights in 3D \n",
    "    data_complete: A numpy array of Nx4 with the first column being all 1s, second and third column \n",
    "                   consists of N points generated uniformly between llim and ulim and the last column\n",
    "                   contains the categories to be learnt\n",
    "                   \n",
    "    output: Returns a tuple with following elements at respective indices-\n",
    "        index        element\n",
    "        0 -          a column vector 3x1 containing the final weights\n",
    "        1 -          number of iterations until convergence\n",
    "    \"\"\"\n",
    "    missclass_dataset = ident_misclass_pts(data_complete, weight_3D_init)[0]\n",
    "    no_of_iterations=0\n",
    "    while (missclass_dataset.size!=0):\n",
    "        n = random.randint(0,missclass_dataset.shape[0]-1)\n",
    "        weight_3D_init = weight_update(weight_3D_init, missclass_dataset[n])\n",
    "        missclass_dataset = ident_misclass_pts(data_complete, weight_3D_init)[0]\n",
    "        no_of_iterations = no_of_iterations + 1\n",
    "    final_weight = weight_3D_init\n",
    "    #visual_perceptron(data_complete, final_weight)\n",
    "    return (final_weight,no_of_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the average Ein and Eout\n",
    "nsims = 1000\n",
    "Ein = 0\n",
    "Eout = 0\n",
    "llim = -1\n",
    "ulim = 1\n",
    "no_of_iterations = 0\n",
    "N_reg = 100\n",
    "N_pla = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average in sample error is: 0.033379999999999986\n",
      "The average out of sample error is: 0.039771\n"
     ]
    }
   ],
   "source": [
    "# Computing the average in-sample and out of sample error\n",
    "for i in range(nsims):\n",
    "    target_weight_3D = np.array([[np.random.uniform(-1,1)],[np.random.uniform(-1,1)],[np.random.uniform(-1,1)]])\n",
    "    data_complete = gen_data_perceptron(llim,ulim,target_weight_3D,N_reg)\n",
    "    data_complete_test = gen_data_perceptron(llim,ulim,target_weight_3D,10*N_reg)\n",
    "    \n",
    "    # Computing the weights using Linear Regression Algorithm and the Ein for this step\n",
    "    final_weight_reg = lin_reg(data_complete)\n",
    "    Ein = Ein + ident_misclass_pts(data_complete, final_weight_reg)[1]\n",
    "    Eout = Eout + ident_misclass_pts(data_complete_test, final_weight_reg)[1]\n",
    "    \n",
    "print(\"The average in sample error is:\", Ein/nsims)\n",
    "print(\"The average out of sample error is:\", Eout/nsims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of iterations for PLA to converge: 3.161\n"
     ]
    }
   ],
   "source": [
    "# Using Regression as the starting point for PLA\n",
    "for i in range(nsims):\n",
    "    target_weight_3D = np.array([[np.random.uniform(-1,1)],[np.random.uniform(-1,1)],[np.random.uniform(-1,1)]])\n",
    "    data_complete = gen_data_perceptron(llim,ulim,target_weight_3D,N_pla)\n",
    "    \n",
    "    # Computing the weights using Linear Regression Algorithm and using them as initial weights for PLA\n",
    "    final_weight_reg = lin_reg(data_complete)\n",
    "    pla_results = PLA(data_complete, final_weight_reg)\n",
    "    no_of_iterations = no_of_iterations + pla_results[1]\n",
    "print(\"The average number of iterations for PLA to converge:\", no_of_iterations/nsims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
